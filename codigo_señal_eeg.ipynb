{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read EEG data and find the start point of the spots\n",
    "\n",
    "We are going to use [MNE-Python](https://www.martinos.org/mne/stable/index.html), which is a software exploring, visualizing, and analyzing human neurophysiological data: MEG, EEG, sEEG, ECoG, and more.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "We are goin to read Brain Vision files, doc is [here](https://www.martinos.org/mne/stable/manual/io.html#brainvision-vhdr-vmrk-eeg).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from eeg_example\\Neuromarketing3850.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    }
   ],
   "source": [
    "import mne.io as io_eeg\n",
    "\n",
    "#we are going to read an example eeg which is in the folder EEG_example. The method returns a RAW men object\n",
    "filename = 'eeg_example\\\\Neuromarketing3850.vhdr'\n",
    "eeg_object = io_eeg.read_raw_brainvision(filename) #the remaining parameters are left as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Object\n",
    "\n",
    "The raw object has a lot of methods and some atributes. The most important atributes are:\n",
    " * ch_names: Channel names.\n",
    "\n",
    " * n_times: Number of time points.\n",
    "\n",
    " * times: Time points.\n",
    "\n",
    " * info: (dict) [Measurement info](https://www.martinos.org/mne/stable/generated/mne.Info.html#mne.Info). This data structure behaves like a dictionary. It contains all metadata that is available for a recording.\n",
    "\n",
    " * preload: (bool) Indicates whether raw data are in memory.\n",
    "\n",
    " * verbose : (bool, str, int, or None) If not None, override default verbose level (see mne.verbose() and Logging documentation for more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2']\n"
     ]
    }
   ],
   "source": [
    "print(eeg_object.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240140\n"
     ]
    }
   ],
   "source": [
    "print(eeg_object.n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = eeg_object.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240140,)\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = eeg_object.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 240140)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(eeg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 16 non-empty fields\n",
      "    bads : list | 0 items\n",
      "    ch_names : list | Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, ...\n",
      "    chs : list | 31 items (EEG: 31)\n",
      "    comps : list | 0 items\n",
      "    custom_ref_applied : bool | False\n",
      "    dev_head_t : Transform | 3 items\n",
      "    events : list | 0 items\n",
      "    highpass : float | 0.0 Hz\n",
      "    hpi_meas : list | 0 items\n",
      "    hpi_results : list | 0 items\n",
      "    lowpass : float | 140.0 Hz\n",
      "    meas_date : tuple | 2019-02-21 13:43:42 GMT\n",
      "    nchan : int | 31\n",
      "    proc_history : list | 0 items\n",
      "    projs : list | 0 items\n",
      "    sfreq : float | 500.0 Hz\n",
      "    acq_pars : NoneType\n",
      "    acq_stim : NoneType\n",
      "    ctf_head_t : NoneType\n",
      "    description : NoneType\n",
      "    dev_ctf_t : NoneType\n",
      "    device_info : NoneType\n",
      "    dig : NoneType\n",
      "    experimenter : NoneType\n",
      "    file_id : NoneType\n",
      "    gantry_angle : NoneType\n",
      "    helium_info : NoneType\n",
      "    hpi_subsystem : NoneType\n",
      "    kit_system_id : NoneType\n",
      "    line_freq : NoneType\n",
      "    meas_id : NoneType\n",
      "    proj_id : NoneType\n",
      "    proj_name : NoneType\n",
      "    subject_info : NoneType\n",
      "    utc_offset : NoneType\n",
      "    xplotter_layout : NoneType\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "info = eeg_object.info\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Eeg info in a new file called \"Data_Info_Eeg\"\n",
    "from TFG_utils import Load_Eeg_Info\n",
    "\n",
    "Eeg_Data = Load_Eeg_Info(info)    #Data_Info_Eeg --> Eeg_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "# Get frequency\n",
    "from TFG_utils import Get_Frequency\n",
    "\n",
    "sfreq = Get_Frequency(Eeg_Data)    #freq [hz]\n",
    "print(sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'take_vmrk_file' from 'TFG_utils' (C:\\Users\\noemi\\OneDrive\\Escritorio\\UNI\\TFG\\codigo Noemi\\TFG-NOEMI\\TFG_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-13f95b126016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTFG_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtake_vmrk_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvmrk_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtake_vmrk_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eeg_example'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmrk_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'take_vmrk_file' from 'TFG_utils' (C:\\Users\\noemi\\OneDrive\\Escritorio\\UNI\\TFG\\codigo Noemi\\TFG-NOEMI\\TFG_utils.py)"
     ]
    }
   ],
   "source": [
    "from TFG_utils import take_vmrk_file\n",
    " \n",
    "vmrk_file = take_vmrk_file('eeg_example')\n",
    "\n",
    "print(vmrk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Start and end\n",
    "import os\n",
    "from TFG_utils import Get_Start_End\n",
    "\n",
    "start_end = Get_Start_End('eeg_example\\\\' + vmrk_file)\n",
    "print(start_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_times_sec = [0, 60, 120, 180, 226, 287, 347] # Time at which begins each spot (in sec)\n",
    "print(spots_times_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from TFG_utils import spot_samples\n",
    "spot_samples = spot_samples(start_end,sfreq, spots_times_sec)\n",
    "print(spot_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "import numpy as np\n",
    "ch=2 #channel to represent\n",
    "ini= int(60)*int(sfreq) # 1 min of period basal activity, in samples\n",
    "#print(ini)\n",
    "i = 0\n",
    "#print(spot_samples[i])\n",
    "x=np.arange(spot_samples[i]-ini,spot_samples[i])\n",
    "plt.plot(x,eeg[ch,spot_samples[i]-ini:spot_samples[i]])\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    " #print(len(spot_samples))\n",
    "while i < (len(spot_samples)-1):\n",
    "    x=np.arange(spot_samples[i],spot_samples[i+1])\n",
    "    plt.plot(x,eeg[ch,spot_samples[i]:spot_samples[i+1]])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notch filter #\n",
    "\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "fs= int(sfreq) # Hz, sampling frequency\n",
    "\n",
    "t = eeg_object.times #generate temporal axes\n",
    "\n",
    "## Design notch filter\n",
    "\n",
    "f0 = 50  # Frequency to be removed from signal (Hz)\n",
    "Q = 30.0  # Quality factor\n",
    "\n",
    "b,a = signal.iirnotch(f0,Q,fs)\n",
    "eeg_ch1_notch = signal.filtfilt(b, a, eeg[10,0:len(t)])\n",
    "plt.figure()\n",
    "plt.plot(eeg_ch1_notch[0:len(t)])\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < (len(spot_samples)-1):\n",
    "    x=np.arange(spot_samples[i],spot_samples[i+1])\n",
    "    plt.plot(x,eeg_ch1_notch[spot_samples[i]:spot_samples[i+1]])\n",
    "    i = i + 1\n",
    "\n",
    "# Frequency response\n",
    "freq, h = signal.freqz(b, a, fs=fs)\n",
    "# Plot        \n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "ax[0].plot(freq, 20*np.log10(abs(h)), color='blue')\n",
    "ax[0].set_title(\"Frequency Response\")\n",
    "ax[0].set_ylabel(\"Amplitude (dB)\", color='blue')\n",
    "ax[0].set_xlim([0, 100])\n",
    "ax[0].set_ylim([-25, 10])\n",
    "ax[0].grid()\n",
    "ax[1].plot(freq, np.unwrap(np.angle(h))*180/np.pi, color='green')\n",
    "ax[1].set_ylabel(\"Angle (degrees)\", color='green')\n",
    "ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "ax[1].set_xlim([0, 100])\n",
    "ax[1].set_yticks([-90, -60, -30, 0, 30, 60, 90])\n",
    "ax[1].set_ylim([-90, 90])\n",
    "ax[1].grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design band pass filter            \n",
    "f1= 2\n",
    "f2= 30\n",
    "numtaps=64\n",
    "b=signal.firwin(numtaps, [f1, f2], pass_zero=False,fs=fs)\n",
    "eeg_ch1_bp = signal.filtfilt(b, 1, eeg_ch1_notch)\n",
    "plt.figure()\n",
    "plt.plot(eeg_ch1_bp[0:len(t)])\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    "\n",
    "### plot -> noth + band pass filter\n",
    "i = 0\n",
    "\n",
    "while i < (len(spot_samples)-1):\n",
    "    x=np.arange(spot_samples[i],spot_samples[i+1])\n",
    "    plt.plot(x,eeg_ch1_bp[spot_samples[i]:spot_samples[i+1]])\n",
    "    i = i + 1\n",
    "\n",
    "# Frequency response\n",
    "freq, h = signal.freqz(b, a, fs=fs)\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "ax[0].plot(freq, 20*np.log10(abs(h)), color='blue')\n",
    "ax[0].set_title(\"Frequency Response\")\n",
    "ax[0].set_ylabel(\"Amplitude (dB)\", color='blue')\n",
    "ax[0].set_xlim([0, 100])\n",
    "ax[0].set_ylim([-50, 50])\n",
    "ax[0].grid()\n",
    "ax[1].plot(freq, np.unwrap(np.angle(h))*180/np.pi, color='green')\n",
    "ax[1].set_ylabel(\"Angle (degrees)\", color='green')\n",
    "ax[1].set_xlabel(\"Frequency (Hz)\")\n",
    "ax[1].set_xlim([0, 100])\n",
    "#ax[1].set_yticks([-90, -60, -30, 0, 30, 60, 90])\n",
    "#ax[1].set_ylim([-4000, 50])\n",
    "ax[1].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### band pass filter     VS    notch - band pass filter ###\n",
    "\n",
    "## Design band pass filter            \n",
    "f1= 2\n",
    "f2= 30\n",
    "numtaps=64\n",
    "b=signal.firwin(numtaps, [f1, f2], pass_zero=False,fs=fs)\n",
    "eeg_ch1_bp = signal.filtfilt(b, 1,  eeg[10,0:len(t)])\n",
    "eeg_ch1_bp_notch = signal.filtfilt(b, 1, eeg_ch1_notch)\n",
    "## graficas individuales Notch + bp     y    bp\n",
    "plt.figure()\n",
    "plt.plot(eeg_ch1_bp_notch[0:len(t)])\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    "plt.figure()\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    "plt.plot(eeg_ch1_bp[0:len(t)], color = 'orange')\n",
    "\n",
    "### grafica superpuesta para comparar ambos resultados\n",
    "plt.figure()\n",
    "plt.plot(eeg_ch1_bp_notch[0:len(t)])\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    "plt.plot(eeg_ch1_bp[5000:len(t)+5000], color = 'orange')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.figure()\n",
    "i=0\n",
    "eeg_channels_array = [] #  empty regular list\n",
    "while i < 31:\n",
    "    ##  notch    No lo aplicamos\n",
    "    ##  bp\n",
    "    f1= 2\n",
    "    f2= 30\n",
    "    numtaps=64\n",
    "    b=signal.firwin(numtaps, [f1, f2], pass_zero=False,fs=int(sfreq))\n",
    "    eeg_chi_bp = signal.filtfilt(b, 1, eeg[i,0:len(t)])\n",
    "\n",
    "    eeg_channel = eeg_chi_bp # for instance\n",
    "    eeg_channels_array.append(eeg_channel)\n",
    "    i += 1\n",
    "    \n",
    "np_channels_array = np.array(eeg_channels_array)\n",
    "print(np_channels_array.shape)\n",
    "\n",
    "pca = PCA(n_components=4)      \n",
    "principalComponents = pca.fit(np_channels_array)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))      \n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "\n",
    "components = pca.transform(np_channels_array)\n",
    "filtered_channels_array = pca.inverse_transform(components)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np_channels_array[10, 0:len(t)])\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(filtered_channels_array[2, 0:len(t)], color = \"brown\")\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('EEG')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#######  CANALES DE INTERES : [F3, F7, F4, F8]\n",
    "\n",
    "eeg_interest_channels = np.array([filtered_channels_array[2], filtered_channels_array[3], filtered_channels_array[28], filtered_channels_array[29]])\n",
    "\n",
    "plt.plot(filtered_channels_array[2])\n",
    "\n",
    "i=0\n",
    "while i < 4:\n",
    "    plt.figure()\n",
    "    plt.plot(eeg_interest_channels[i, spot_samples[2]: spot_samples[3]])    # distintos canales señal anterior al 1er anuncio\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel('EEG')\n",
    "    if i == 0:\n",
    "        fig.suptitle(\"Canal 'F3'\")\n",
    "    i += 1\n",
    "    \n",
    "########## Anuncios + prev #########\n",
    "Prev = []\n",
    "Anuncio1 = []\n",
    "Anuncio2 = []\n",
    "Anuncio3 = []\n",
    "Anuncio4 = []\n",
    "Anuncio5 = []\n",
    "Anuncio6 = []\n",
    "\n",
    "j = 0\n",
    "while j < 4:\n",
    "    i = 0\n",
    "    while i < (len(spot_samples)-1):    \n",
    "        x=np.arange(spot_samples[i],spot_samples[i+1])\n",
    "        if i == 0:\n",
    "            Prev.append(eeg_interest_channels[j, 0:spot_samples[i]])\n",
    "            Anuncio1.append(eeg_interest_channels[j, spot_samples[i]:spot_samples[i+1]])\n",
    "        elif i == 1:\n",
    "            Anuncio2.append(eeg_interest_channels[j, spot_samples[i]:spot_samples[i+1]])\n",
    "        elif i == 2:\n",
    "            Anuncio3.append(eeg_interest_channels[j, spot_samples[i]:spot_samples[i+1]])\n",
    "        elif i == 3:\n",
    "            Anuncio4.append(eeg_interest_channels[j, spot_samples[i]:spot_samples[i+1]])\n",
    "        elif i == 4:\n",
    "            Anuncio5.append(eeg_interest_channels[j, spot_samples[i]:spot_samples[i+1]])\n",
    "        elif i == 5:\n",
    "            Anuncio6.append(eeg_interest_channels[j, spot_samples[i]:spot_samples[i+1]])\n",
    "        i += 1\n",
    "    j += 1\n",
    "    \n",
    "np_prev = np.array(Prev)\n",
    "np_anuncio1 = np.array(Anuncio1)\n",
    "np_anuncio2 = np.array(Anuncio2)\n",
    "np_anuncio3 = np.array(Anuncio3)\n",
    "np_anuncio4 = np.array(Anuncio4)\n",
    "np_anuncio5 = np.array(Anuncio5)\n",
    "np_anuncio6 = np.array(Anuncio6) \n",
    "\n",
    "np_anuncios_t = [np_prev, np_anuncio1, np_anuncio2, np_anuncio3, np_anuncio4, np_anuncio5, np_anuncio6]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(eeg[2, 0:len(t/2)])\n",
    "plt.plot(eeg[3, 0:len(t/2)])\n",
    "plt.plot(eeg[28, 0:len(t/2)])\n",
    "plt.plot(eeg[29, 0:len(t/2)])\n",
    "plt.figure(figsize = (8,4))\n",
    "for x in eeg_interest_channels:\n",
    "    plt.plot(x[0:len(t/2)])\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel('EEG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import scipy\n",
    "import statistics as stats\n",
    "\n",
    "potencias_estimadas_prev = []\n",
    "potencias_estimadas_anuncio1 = []\n",
    "potencias_estimadas_anuncio2 = []\n",
    "potencias_estimadas_anuncio3 = []\n",
    "potencias_estimadas_anuncio4 = []\n",
    "potencias_estimadas_anuncio5 = []\n",
    "potencias_estimadas_anuncio6 = []\n",
    "\n",
    "#Nsim = 50\n",
    "\n",
    "j=0\n",
    "while j < 7:   ## anuncios + prev\n",
    "    i = 0\n",
    "    while i < 4:    # canales\n",
    "        x = np_anuncios_t[j][i, 0:30000]\n",
    "        f2, Pxx3 =scipy.signal.welch(x, fs = int(sfreq), window='hamming', nperseg=128, nfft=1024)\n",
    "        l=0\n",
    "        alpha_frec = []\n",
    "        while l < (len(f2)):\n",
    "            if f2[l] >= 8:\n",
    "                if f2[l] <= 12: \n",
    "                    alpha_frec.append(l)  \n",
    "            l += 1\n",
    "        \n",
    "        sumatorio_pxx3 = 0\n",
    "        for k in Pxx3:\n",
    "            sumatorio_pxx3 += k\n",
    "        \n",
    "        pxx3_rel = []\n",
    "        for r in Pxx3:\n",
    "            pxx3_rel.append(r/sumatorio_pxx3) \n",
    "       \n",
    "        potencia_estimada = 0\n",
    "        for x in alpha_frec:\n",
    "             potencia_estimada += pxx3_rel[x]\n",
    "        potencia_estimada_rel = potencia_estimada\n",
    "        if j == 3 :\n",
    "            plt.figure()\n",
    "            plt.plot(f2[0:50], pxx3_rel[0:50])\n",
    "            plt.xlabel('Frecuencia [Hz]')\n",
    "            plt.ylabel('Potencia espectral estimada' + str(i))\n",
    "        \n",
    "        if j == 0:\n",
    "            potencias_estimadas_prev.append(potencia_estimada_rel)\n",
    "        elif j == 1:\n",
    "            potencias_estimadas_anuncio1.append(potencia_estimada_rel)\n",
    "        elif j == 2:\n",
    "            potencias_estimadas_anuncio2.append(potencia_estimada_rel)\n",
    "        elif j ==3:\n",
    "            potencias_estimadas_anuncio3.append(potencia_estimada_rel)\n",
    "        elif j == 4:\n",
    "            potencias_estimadas_anuncio4.append(potencia_estimada_rel)\n",
    "        elif j == 5:\n",
    "            potencias_estimadas_anuncio5.append(potencia_estimada_rel)\n",
    "        elif j ==6:\n",
    "            potencias_estimadas_anuncio6.append(potencia_estimada_rel)\n",
    "        i += 1\n",
    "    j += 1\n",
    "\n",
    "labels = [\"Actividad normal \", \"Anuncio 1\", \"Anuncio 2\", \"Anuncio 3\", \"Anuncio 4\", \"Anuncio 5\", \"Anuncio 6\"]\n",
    "potencias_estimadas_f3 = [potencias_estimadas_prev[0], potencias_estimadas_anuncio1[0], potencias_estimadas_anuncio2[0], potencias_estimadas_anuncio3[0], potencias_estimadas_anuncio4[0], potencias_estimadas_anuncio5[0], potencias_estimadas_anuncio6[0]]\n",
    "potencias_estimadas_f7 = [potencias_estimadas_prev[1], potencias_estimadas_anuncio1[1], potencias_estimadas_anuncio2[1], potencias_estimadas_anuncio3[1], potencias_estimadas_anuncio4[1], potencias_estimadas_anuncio5[1], potencias_estimadas_anuncio6[1]]\n",
    "potencias_estimadas_f4 = [potencias_estimadas_prev[2], potencias_estimadas_anuncio1[2], potencias_estimadas_anuncio2[2], potencias_estimadas_anuncio3[2], potencias_estimadas_anuncio4[2], potencias_estimadas_anuncio5[2], potencias_estimadas_anuncio6[2]]\n",
    "potencias_estimadas_f8 = [potencias_estimadas_prev[3], potencias_estimadas_anuncio1[3], potencias_estimadas_anuncio2[3], potencias_estimadas_anuncio3[3], potencias_estimadas_anuncio4[3], potencias_estimadas_anuncio5[3], potencias_estimadas_anuncio6[3]]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.17  # the width of the bars\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - 0.2, potencias_estimadas_f3, width, label='F3')\n",
    "rects2 = ax.bar(x , potencias_estimadas_f7, width, label='F7')\n",
    "rects1 = ax.bar(x + 0.2, potencias_estimadas_f4, width, label='F4')\n",
    "rects2 = ax.bar(x + 0.4, potencias_estimadas_f8, width, label='F8')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Potencia estimada')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######  AWI   #####\n",
    "#AW = GFPa_right - GFPa_left\n",
    "\n",
    "GFPa_left_prev = (potencias_estimadas_f3[0]+potencias_estimadas_f7[0])/2\n",
    "GFPa_right_prev = (potencias_estimadas_f4[0]+potencias_estimadas_f8[0])/2\n",
    "\n",
    "GFPa_left_anuncio1 = (potencias_estimadas_f3[1]+potencias_estimadas_f7[1])/2\n",
    "GFPa_right_anuncio1 = (potencias_estimadas_f4[1]+potencias_estimadas_f8[1])/2\n",
    "\n",
    "GFPa_left_anuncio2 = (potencias_estimadas_f3[2]+potencias_estimadas_f7[2])/2\n",
    "GFPa_right_anuncio2 = (potencias_estimadas_f4[2]+potencias_estimadas_f8[2])/2\n",
    "\n",
    "GFPa_left_anuncio6 = (potencias_estimadas_f3[3]+potencias_estimadas_f7[3])/2\n",
    "GFPa_right_anuncio6 = (potencias_estimadas_f4[3]+potencias_estimadas_f8[3])/2\n",
    "\n",
    "GFPa_left_anuncio3 = (potencias_estimadas_f3[4]+potencias_estimadas_f7[4])/2\n",
    "GFPa_right_anuncio3 = (potencias_estimadas_f4[4]+potencias_estimadas_f8[4])/2\n",
    "\n",
    "GFPa_left_anuncio4 = (potencias_estimadas_f3[5]+potencias_estimadas_f7[5])/2\n",
    "GFPa_right_anuncio4 = (potencias_estimadas_f4[5]+potencias_estimadas_f8[5])/2\n",
    "\n",
    "GFPa_left_anuncio5 = (potencias_estimadas_f3[6]+potencias_estimadas_f7[6])/2\n",
    "GFPa_right_anuncio5 = (potencias_estimadas_f4[6]+potencias_estimadas_f8[6])/2\n",
    "\n",
    "AW_prev = GFPa_right_prev - GFPa_left_prev\n",
    "AW_anuncio1 = GFPa_right_anuncio1 - GFPa_left_anuncio1\n",
    "AW_anuncio2 = GFPa_right_anuncio2 - GFPa_left_anuncio2\n",
    "AW_anuncio3 = GFPa_right_anuncio3 - GFPa_left_anuncio3\n",
    "AW_anuncio4 = GFPa_right_anuncio4 - GFPa_left_anuncio4\n",
    "AW_anuncio5 = GFPa_right_anuncio5 - GFPa_left_anuncio5\n",
    "AW_anuncio6 = GFPa_right_anuncio6 - GFPa_left_anuncio6\n",
    "\n",
    "AW_anuncios = [AW_anuncio1, AW_anuncio2, AW_anuncio3, AW_anuncio4, AW_anuncio5, AW_anuncio6]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "x = np.arange(len(AW_anuncios))\n",
    "plt.plot(AW_anuncios, marker='o', linestyle='--', color='r')\n",
    "ax.set_ylabel('AW Index')\n",
    "ax.set_xticklabels(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
